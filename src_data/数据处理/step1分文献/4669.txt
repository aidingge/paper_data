RT Journal Article
SR 1
A1 江晓原;
TP 人工智能的危险前景
JF 编辑学刊
YR 2015
IS 05
OP 40-41
K1 人工智能;人类;马克斯;霍金;恶魔;奥斯汀;物理极限;
AB <正>进入2015年,关于人工智能的报道和讨论十分热烈,各种有关书籍也纷纷出版。有人甚至已称2015年为"智能机器人从虚拟走向现实的元年",许多人欢欣鼓舞,相信我们已经处在人工智能大突破的前夜。从国内平面媒体和网络上看,那些对人工智能表示警惕乃至郑重发出警告的,基本上都是国外学者。而国内的评论者则普遍发表乐观的言论。2015年初,史蒂芬·霍金、比尔·盖茨和埃隆·马克斯等人签署了一封公开信,呼吁控制人工智能的研发。马克斯认为人工智能会"唤出恶魔",比核武器对人类的威胁还大。霍金则明确断言:"彻底开发人工智能可能导致人类灭亡。"
SN 1007-3884
CN 31-1116/G2
LA 中文;
DS CNKI